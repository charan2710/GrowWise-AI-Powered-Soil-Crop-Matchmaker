{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Model and preprocessing objects saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'updated_soil_fertility.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Selecting required features\n",
    "features = ['Nitrogen', 'Phosphorus', 'Potassium', 'Temperature', 'Humidity', 'pH']\n",
    "X = df[features]\n",
    "\n",
    "# Encoding target variable (Recommendation)\n",
    "label_enc_recommendation = LabelEncoder()\n",
    "df['Recommendation'] = label_enc_recommendation.fit_transform(df['Recommendation'])\n",
    "\n",
    "# Ensure \"Leguminous\" exists in LabelEncoder\n",
    "if \"Leguminous\" not in label_enc_recommendation.classes_:\n",
    "    label_enc_recommendation.classes_ = np.append(label_enc_recommendation.classes_, \"Leguminous\")\n",
    "\n",
    "# Encode 'Type' column\n",
    "df['Type'] = df['Type'].astype(str)\n",
    "type_mapping = {type_name: idx for idx, type_name in enumerate(df['Type'].unique())}\n",
    "inverse_type_mapping = {v: k for k, v in type_mapping.items()}\n",
    "df['Type'] = df['Type'].map(type_mapping)\n",
    "\n",
    "# Define target variables\n",
    "y_recommendation = df['Recommendation']\n",
    "y_type = df['Type']\n",
    "\n",
    "# Feature selection using mutual information\n",
    "selector = SelectKBest(mutual_info_classif, k='all')\n",
    "X_new = selector.fit_transform(X, y_recommendation)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train_rec, y_test_rec = train_test_split(\n",
    "    X_new, y_recommendation, test_size=0.2, random_state=42, stratify=y_recommendation\n",
    ")\n",
    "\n",
    "# Handle class imbalance if necessary\n",
    "if len(np.unique(y_train_rec)) > 1:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train_rec = smote.fit_resample(X_train, y_train_rec)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter tuning for RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train_rec)\n",
    "\n",
    "# Save best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "joblib.dump(best_rf_model, 'soil_recommendation_model.pkl')\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Save label encoder for Recommendation\n",
    "joblib.dump(label_enc_recommendation, 'label_encoder_recommendation.pkl')\n",
    "\n",
    "# Save Type mappings\n",
    "joblib.dump(type_mapping, 'type_mapping.pkl')\n",
    "joblib.dump(inverse_type_mapping, 'inverse_type_mapping.pkl')\n",
    "\n",
    "print(\"Model and preprocessing objects saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully in 'saved_models' folder!\n",
      "Saved files:\n",
      " - inverse_type_mapping.pkl\n",
      " - label_encoder.pkl\n",
      " - plant_category_model.pkl\n",
      " - plant_type_model.pkl\n",
      " - scaler.pkl\n",
      " - type_mapping.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'updated_soil_fertility.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Features and target selection\n",
    "features = ['Nitrogen', 'Phosphorus', 'Potassium', 'Temperature', 'Humidity', 'pH']\n",
    "X = df[features]\n",
    "\n",
    "# Encode Recommendation (Leguminous/General)\n",
    "label_enc_recommendation = LabelEncoder()\n",
    "df['Recommendation'] = label_enc_recommendation.fit_transform(df['Recommendation'])\n",
    "\n",
    "# Encode Type (Specific Plant Name)\n",
    "df['Type'] = df['Type'].astype(str)\n",
    "type_mapping = {name: idx for idx, name in enumerate(df['Type'].unique())}\n",
    "inverse_type_mapping = {v: k for k, v in type_mapping.items()}\n",
    "df['Type'] = df['Type'].map(type_mapping)\n",
    "\n",
    "# Target Variables\n",
    "y_recommendation = df['Recommendation']\n",
    "y_type = df['Type']\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(f_classif, k='all')\n",
    "X_new = selector.fit_transform(X, y_recommendation)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train_rec, y_test_rec = train_test_split(X_new, y_recommendation, test_size=0.2, random_state=42, stratify=y_recommendation)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_rec = smote.fit_resample(X_train, y_train_rec)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the category model (Leguminous/General)\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=4, random_state=42)\n",
    "rf_model.fit(X_train, y_train_rec)\n",
    "\n",
    "# Ensure models directory exists\n",
    "model_dir = \"saved_models\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save category model & preprocessing tools\n",
    "joblib.dump(rf_model, os.path.join(model_dir, \"plant_category_model.pkl\"))\n",
    "joblib.dump(scaler, os.path.join(model_dir, \"scaler.pkl\"))\n",
    "joblib.dump(label_enc_recommendation, os.path.join(model_dir, \"label_encoder.pkl\"))\n",
    "\n",
    "# Train the type model (Specific plant type)\n",
    "X_train_type, X_test_type, y_train_type, y_test_type = train_test_split(X_new, y_type, test_size=0.2, random_state=42, stratify=y_type)\n",
    "type_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "type_model.fit(X_train_type, y_train_type)\n",
    "\n",
    "# Save type model & mappings\n",
    "joblib.dump(type_model, os.path.join(model_dir, \"plant_type_model.pkl\"))\n",
    "joblib.dump(type_mapping, os.path.join(model_dir, \"type_mapping.pkl\"))\n",
    "joblib.dump(inverse_type_mapping, os.path.join(model_dir, \"inverse_type_mapping.pkl\"))\n",
    "\n",
    "print(\"Models saved successfully in 'saved_models' folder!\")\n",
    "\n",
    "# Verify files exist\n",
    "print(\"Saved files:\")\n",
    "for file in os.listdir(model_dir):\n",
    "    print(f\" - {file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
